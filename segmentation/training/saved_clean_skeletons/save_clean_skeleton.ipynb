{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7bbe41e-af5d-4a28-a924-14d372136f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % matplotlib inline\n",
    "from neuprint import Client, skeleton\n",
    "from neuprint import fetch_synapses, NeuronCriteria as NC, SynapseCriteria as SC\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import random\n",
    "from os.path import isfile\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "token_id = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImdhcnJldHQuc2FnZXJAeWFsZS5lZHUiLCJsZXZlbCI6Im5vYXV0aCIsImltYWdlLXVybCI6Imh0dHBzOi8vbGgzLmdvb2dsZXVzZXJjb250ZW50LmNvbS9hLS9BT2gxNEdpTGNqZXlHYWNnS3NPcTgzdDNfczBoTU5sQUtlTkljRzdxMkU5Rz1zOTYtYz9zej01MD9zej01MCIsImV4cCI6MTgwMTAxNzUwNn0.dzq7Iy01JwSWbKq-Qvi8ov7Hwr0-ozpYeSnOsUD-Mx0\"\n",
    "np.set_printoptions(precision=5, suppress=True)  # suppress scientific float notation\n",
    "home_dir = '/home/gsager56/hemibrain/clean_mito_code'\n",
    "c = Client('neuprint.janelia.org', dataset='hemibrain:v1.2.1', token=token_id)\n",
    "neuron_quality = pd.read_csv(home_dir + '/saved_data/neuron_quality.csv')\n",
    "neuron_quality_np = neuron_quality.to_numpy()\n",
    "server = 'http://hemibrain-dvid.janelia.org'\n",
    "\n",
    "# import utils file\n",
    "spec = importlib.util.spec_from_file_location('utils', home_dir+'/util_files/utils.py')\n",
    "utils = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(utils)\n",
    "\n",
    "# import skel_clean_utils file\n",
    "spec = importlib.util.spec_from_file_location('skel_clean_utils', home_dir+'/util_files/skel_clean_utils.py')\n",
    "skel_clean_utils = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(skel_clean_utils)\n",
    "\n",
    "# import GLM_utils file\n",
    "spec = importlib.util.spec_from_file_location('GLM_utils', home_dir+'/util_files/GLM_utils.py')\n",
    "GLM_utils = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(GLM_utils)\n",
    "\n",
    "# import config file\n",
    "spec = importlib.util.spec_from_file_location('config', home_dir+'/util_files/config.py')\n",
    "config = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(config)\n",
    "\n",
    "node_class_dict = config.node_class_dict\n",
    "analyze_neurons  = config.analyze_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e41fa9b-b7dc-4ff0-ac4d-61a99f7a42c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LC4',\n",
       " 'LC6',\n",
       " 'LC9',\n",
       " 'LC10',\n",
       " 'LC11',\n",
       " 'LC12',\n",
       " 'LC13',\n",
       " 'LC14',\n",
       " 'LC15',\n",
       " 'LC16',\n",
       " 'LC17',\n",
       " 'LC18',\n",
       " 'LC20',\n",
       " 'LC21',\n",
       " 'LC22',\n",
       " 'LC24',\n",
       " 'LC25',\n",
       " 'LC26',\n",
       " 'LC27',\n",
       " 'LC29',\n",
       " 'LC31',\n",
       " 'LC36']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7299fc31-f1f6-437a-b3d2-57ca6ef31093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288893591 LC16\n"
     ]
    }
   ],
   "source": [
    "    bodyId, neuron_type = neuron_quality_np[1218,[0,1]]\n",
    "    new_skel_file = home_dir + f'/saved_clean_skeletons/s_pandas_{bodyId}_{neuron_type}_200nm.csv'\n",
    "    if isfile(new_skel_file) and neuron_quality.iloc[i_neuron]['has_dendrite']:\n",
    "        s_pandas = pd.read_csv(new_skel_file)\n",
    "        s_np = s_pandas.to_numpy()\n",
    "        node_classes = s_pandas['node_classes'].to_numpy()\n",
    "        if sum(node_classes == node_class_dict['dendrite']) == 0:\n",
    "            print(bodyId, neuron_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d196e6-f45b-479c-86bb-f7078b9687c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <ssl.SSLSocket fd=62, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.22.86.239', 35024), raddr=('206.241.0.102', 443)>\n",
      "ResourceWarning: unclosed <ssl.SSLSocket fd=62, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.22.86.239', 35024), raddr=('206.241.0.102', 443)>\n",
      "Exception ignored in: <ssl.SSLSocket fd=61, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.22.86.239', 35014), raddr=('206.241.0.102', 443)>\n",
      "ResourceWarning: unclosed <ssl.SSLSocket fd=61, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.22.86.239', 35014), raddr=('206.241.0.102', 443)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# import skel_clean_utils file\n",
    "spec = importlib.util.spec_from_file_location('skel_clean_utils', home_dir+'/util_files/skel_clean_utils.py')\n",
    "skel_clean_utils = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(skel_clean_utils)\n",
    "\n",
    "std_vals = pd.read_csv(home_dir + '/saved_data/trivial_leaf_std.csv').to_numpy()\n",
    "mean_vals = pd.read_csv(home_dir + '/saved_data/trivial_leaf_mean.csv').to_numpy()\n",
    "betas = pd.read_csv(home_dir + '/saved_data/trivial_leaf_betas.csv').to_numpy()\n",
    "\n",
    "for i_neuron in np.where( np.isin(neuron_quality_np[:,1], analyze_neurons) )[0]:\n",
    "    t0 = time.time()\n",
    "    bodyId, neuron_type = neuron_quality_np[i_neuron,[0,1]]\n",
    "    skel_file = home_dir + f'/saved_neuron_skeletons/s_pandas_{bodyId}_{neuron_type}_200nm.csv'\n",
    "    new_skel_file = home_dir + f'/saved_clean_skeletons/s_pandas_{bodyId}_{neuron_type}_200nm.csv'\n",
    "    if isfile(skel_file) and not isfile(new_skel_file):\n",
    "        old_s_pandas = c.fetch_skeleton( bodyId, format='pandas', heal=True, with_distances=False) # I will heal the skeleton later\n",
    "        node_classes, important_nodes = skel_clean_utils.classify_nodes(old_s_pandas, fetch_synapses(NC(bodyId=bodyId)), neuron_quality.iloc[i_neuron])\n",
    "        if node_classes is not None:\n",
    "            s_pandas = pd.read_csv(skel_file)\n",
    "            assert len(s_pandas) > 10\n",
    "            s_pandas = skel_clean_utils.heal_resampled_skel(s_pandas, bodyId)\n",
    "            skeleton.reorient_skeleton( s_pandas, rowId = important_nodes['root node'] )\n",
    "\n",
    "            s_np = s_pandas.to_numpy()\n",
    "            leaf_nodes, branch_nodes = utils.find_leaves_and_branches( s_np )\n",
    "            keep_bool = np.ones( len(s_np), dtype=bool )\n",
    "            for i_leaf, leaf_node in enumerate(leaf_nodes):\n",
    "                leaf_idxs = utils.get_down_idxs(s_np, leaf_node, np.isin(s_np[:,0], branch_nodes))\n",
    "                leaf_length = np.max( np.sqrt( np.sum( (s_np[leaf_idxs,:][:,[1,2,3]] - s_np[leaf_idxs[-1],[1,2,3]][np.newaxis,:])**2, axis=1) ) ) - s_np[leaf_idxs[-1],4]\n",
    "                if leaf_length - (s_np[leaf_idxs[0],4]*2) <= (91.439 / 8):\n",
    "                    keep_bool[ leaf_idxs[:-1] ] = False # this is a trivial leaf\n",
    "            s_pandas = pd.DataFrame( data = s_np[ keep_bool ], columns = s_pandas.columns )\n",
    "            s_np = s_pandas.to_numpy()\n",
    "            \n",
    "            # make sure all the leaves can get to the root\n",
    "            leaf_nodes, branch_nodes = utils.find_leaves_and_branches( s_np )\n",
    "            for node in leaf_nodes:\n",
    "                idx = np.where(s_np[:,0] == node)[0][0]\n",
    "                while s_np[idx,5] != -1:\n",
    "                    idx = np.where(s_np[:,0] == s_np[idx,5])[0][0]\n",
    "                    \n",
    "            # eliminated nodes with the same coordinate\n",
    "            del_idxs = [1]\n",
    "            while len(del_idxs) > 0:\n",
    "                skel_coords = s_np[:,[1,2,3]]\n",
    "                row_cols = np.array( [ [] for _ in range(2) ] , dtype=int).T\n",
    "                for row in range( len(s_np)-1 ):\n",
    "                    cols = np.where( np.all(skel_coords[row].reshape((1,3)) == skel_coords[row+1:],axis=1) )[0]\n",
    "                    if len(cols) >= 2:\n",
    "                        # figure out who is connected to who\n",
    "                        same_coord_idxs = np.append(row,cols+row+1)\n",
    "                        same_coord_nodes = s_np[same_coord_idxs,0]\n",
    "                        same_coord_down_nodes = s_np[same_coord_idxs,5]\n",
    "                        if np.any( np.isin( same_coord_down_nodes, same_coord_nodes) ):\n",
    "                            i_idx = np.where( np.isin( same_coord_down_nodes, same_coord_nodes) )[0][0]\n",
    "                            j_idx = np.where( same_coord_down_nodes[i_idx] == same_coord_nodes )[0][0]\n",
    "                            assert s_np[ same_coord_idxs[i_idx], 5] == s_np[ same_coord_idxs[j_idx], 0]\n",
    "\n",
    "                            this_row, this_col = s_np[same_coord_idxs[[i_idx,j_idx]], 0]\n",
    "                            if this_row not in row_cols and this_col not in row_cols:\n",
    "                                row_cols = np.append( row_cols, [[this_row,this_col]], axis=0)\n",
    "                    elif len(cols)==1:\n",
    "                        this_row = s_np[row,0]\n",
    "                        this_col = s_np[cols[0]+row+1,0]\n",
    "                        if this_row not in row_cols and this_col not in row_cols:\n",
    "                            row_cols = np.append( row_cols, [[this_row,this_col]], axis=0)\n",
    "                assert len(np.unique(row_cols)) == len(row_cols.flatten())\n",
    "                del_idxs = []\n",
    "                for row_node, col_node in row_cols:\n",
    "                    row = np.where( s_np[:,0] == row_node )[0][0]\n",
    "                    col = np.where( s_np[:,0] == col_node )[0][0]\n",
    "\n",
    "                    assert np.all( skel_coords[row] == skel_coords[col] )\n",
    "                    if s_np[row,5] == s_np[col,0] or s_np[col,5] == s_np[row,0]:\n",
    "                        if s_np[row,5] == s_np[col,0]:\n",
    "                            up_idx, down_idx = row, col\n",
    "                        elif s_np[col,5] == s_np[row,0]:\n",
    "                            down_idx, up_idx = row, col\n",
    "                        assert s_np[up_idx,5] == s_np[down_idx,0]\n",
    "\n",
    "                        if np.sum( s_np[up_idx,0] == s_np[:,5] ) > 0:\n",
    "                            # connect node(s) upstream of up_idx to down_idx \n",
    "                            for idx in np.where( s_np[up_idx,0] == s_np[:,5] )[0]:\n",
    "                                s_pandas.at[idx, 'link'] = s_np[down_idx,0]\n",
    "                        del_idxs.append( up_idx )\n",
    "                if len(del_idxs) > 0:\n",
    "                    s_np = s_np[ ~np.isin( np.arange(len(s_np)), del_idxs ) ]\n",
    "                    s_pandas = pd.DataFrame( data = s_np, columns = s_pandas.columns )\n",
    "            assert len(s_np) == len(s_pandas)\n",
    "            # make sure all the leaves can get to the root\n",
    "            leaf_nodes, branch_nodes = utils.find_leaves_and_branches( s_np )\n",
    "            for node in leaf_nodes:\n",
    "                idx = np.where(s_np[:,0] == node)[0][0]\n",
    "                while s_np[idx,5] != -1:\n",
    "                    idx = np.where(s_np[:,0] == s_np[idx,5])[0][0]\n",
    "            \n",
    "            # change direction of theta and phi to ensure they point down the skeleton\n",
    "            new_cols = np.concatenate( [np.array(s_pandas.columns)[:6], ['distance'], np.array(s_pandas.columns)[6:] ] )\n",
    "            s_pandas = skel_clean_utils.append_distance( s_pandas ) # create a distance field in the dataframe\n",
    "            s_pandas = s_pandas.reindex(columns=new_cols)\n",
    "            s_np = s_pandas.to_numpy()\n",
    "            \n",
    "            frac_wrong = 0.0\n",
    "            for idx in range(len(s_np)):\n",
    "                xyz = np.array( utils.spherical_2_cart(1, s_np[idx,7], s_np[idx,8]) )\n",
    "                xyz = xyz / np.sqrt(np.sum(xyz**2))\n",
    "                if s_np[idx,5] != -1:\n",
    "                    down_idx = np.where(s_np[idx,5] == s_np[:,0] )[0][0]\n",
    "                    down_xyz = s_np[ down_idx, [1,2,3]] - s_np[ idx, [1,2,3] ]\n",
    "                    assert np.sqrt(np.sum(down_xyz**2)) > 0\n",
    "                    down_xyz = down_xyz / np.sqrt(np.sum(down_xyz**2))\n",
    "                    assert np.abs( np.sum(down_xyz * xyz) ) < 1.01, f'{down_xyz}, {xyz}, {np.sum(down_xyz * xyz)}'\n",
    "                    if np.sum(down_xyz * xyz) < 0:\n",
    "                        # xyz is pointed in the wrong direction\n",
    "                        _, theta, phi = utils.cart_2_spherical( -xyz[0], -xyz[1], -xyz[2] )\n",
    "                        s_np[idx,7] = theta\n",
    "                        s_np[idx,8] = phi\n",
    "                        frac_wrong += 1 / len(s_np)\n",
    "            node_classes, important_nodes = skel_clean_utils.classify_nodes(s_pandas, fetch_synapses(NC(bodyId=bodyId)), neuron_quality.iloc[i_neuron])\n",
    "            if node_cl\n",
    "            s_pandas['node_classes'] = node_classes\n",
    "            assert len(s_pandas) > 10\n",
    "            s_pandas.to_csv(new_skel_file, index = False)\n",
    "            print( f'Finished with {bodyId} {neuron_type}' )\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476bc221-856b-4d9a-a940-3467a5d3f5b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4687/2103537015.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d4c06-99e6-4a1d-a96e-43bbc46f5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import skel_clean_utils file\n",
    "spec = importlib.util.spec_from_file_location('skel_clean_utils', home_dir+'/util_files/skel_clean_utils.py')\n",
    "skel_clean_utils = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(skel_clean_utils)\n",
    "\n",
    "std_vals = pd.read_csv(home_dir + '/saved_data/trivial_leaf_std.csv').to_numpy()\n",
    "mean_vals = pd.read_csv(home_dir + '/saved_data/trivial_leaf_mean.csv').to_numpy()\n",
    "betas = pd.read_csv(home_dir + '/saved_data/trivial_leaf_betas.csv').to_numpy()\n",
    "\n",
    "for i_neuron in np.where( np.isin(neuron_quality_np[:,1], analyze_neurons) )[0]:\n",
    "    t0 = time.time()\n",
    "    bodyId, neuron_type = neuron_quality_np[i_neuron,[0,1]]\n",
    "    skel_file = home_dir + f'/saved_neuron_skeletons/s_pandas_{bodyId}_{neuron_type}_200nm.csv'\n",
    "    new_skel_file = home_dir + f'/saved_clean_skeletons/s_pandas_{bodyId}_{neuron_type}_200nm.csv'\n",
    "    if isfile(skel_file) and not isfile(new_skel_file):\n",
    "        old_s_pandas = c.fetch_skeleton( bodyId, format='pandas', heal=True, with_distances=False) # I will heal the skeleton later\n",
    "        node_classes, important_nodes = skel_clean_utils.classify_nodes(old_s_pandas, fetch_synapses(NC(bodyId=bodyId)), neuron_quality.iloc[i_neuron])\n",
    "        if node_classes is not None:\n",
    "            s_pandas = pd.read_csv(skel_file)\n",
    "            s_pandas = skel_clean_utils.heal_resampled_skel(s_pandas, bodyId)\n",
    "            skeleton.reorient_skeleton( s_pandas, rowId = important_nodes['root node'] )\n",
    "\n",
    "            #keep_bool = np.array([False])\n",
    "            #while np.any(~keep_bool):\n",
    "            s_np = s_pandas.to_numpy()\n",
    "            leaf_nodes, branch_nodes = utils.find_leaves_and_branches( s_np )\n",
    "            leaf_space, nodes = skel_clean_utils.get_is_trivial_leaf_space(bodyId, leaf_nodes, mean_vals.shape[1], s_pandas.copy())\n",
    "            zscore_leaf = (leaf_space - mean_vals) / std_vals\n",
    "            q_vals = np.matmul(np.append(np.ones((len(leaf_nodes),1)), zscore_leaf,axis=1), betas.T)[:,0]\n",
    "            probs = 1 / (1 + np.exp(-q_vals))\n",
    "            is_trivial = probs >= 0.6\n",
    "\n",
    "            keep_bool = np.ones( len(s_np), dtype=bool )\n",
    "            for node in nodes[is_trivial]:\n",
    "                keep_bool[ utils.get_down_idxs(s_np, node, np.isin(s_np[:,0],branch_nodes))[:-1] ] = False\n",
    "            s_pandas = pd.DataFrame( data = s_np[ keep_bool ], columns = s_pandas.columns )\n",
    "            s_np = s_pandas.to_numpy()\n",
    "            \n",
    "            # make sure all the leaves can get to the root\n",
    "            leaf_nodes, branch_nodes = utils.find_leaves_and_branches( s_np )\n",
    "            for node in leaf_nodes:\n",
    "                idx = np.where(s_np[:,0] == node)[0][0]\n",
    "                while s_np[idx,5] != -1:\n",
    "                    idx = np.where(s_np[:,0] == s_np[idx,5])[0][0]\n",
    "                    \n",
    "            # eliminated nodes with the same coordinate\n",
    "            del_idxs = [1]\n",
    "            while len(del_idxs) > 0:\n",
    "                skel_coords = s_np[:,[1,2,3]]\n",
    "                row_cols = np.array( [ [] for _ in range(2) ] , dtype=int).T\n",
    "                for row in range( len(s_np)-1 ):\n",
    "                    cols = np.where( np.all(skel_coords[row].reshape((1,3)) == skel_coords[row+1:],axis=1) )[0]\n",
    "                    if len(cols) >= 2:\n",
    "                        # figure out who is connected to who\n",
    "                        same_coord_idxs = np.append(row,cols+row+1)\n",
    "                        same_coord_nodes = s_np[same_coord_idxs,0]\n",
    "                        same_coord_down_nodes = s_np[same_coord_idxs,5]\n",
    "                        if np.any( np.isin( same_coord_down_nodes, same_coord_nodes) ):\n",
    "                            i_idx = np.where( np.isin( same_coord_down_nodes, same_coord_nodes) )[0][0]\n",
    "                            j_idx = np.where( same_coord_down_nodes[i_idx] == same_coord_nodes )[0][0]\n",
    "                            assert s_np[ same_coord_idxs[i_idx], 5] == s_np[ same_coord_idxs[j_idx], 0]\n",
    "\n",
    "                            this_row, this_col = s_np[same_coord_idxs[[i_idx,j_idx]], 0]\n",
    "                            if this_row not in row_cols and this_col not in row_cols:\n",
    "                                row_cols = np.append( row_cols, [[this_row,this_col]], axis=0)\n",
    "                    elif len(cols)==1:\n",
    "                        this_row = s_np[row,0]\n",
    "                        this_col = s_np[cols[0]+row+1,0]\n",
    "                        if this_row not in row_cols and this_col not in row_cols:\n",
    "                            row_cols = np.append( row_cols, [[this_row,this_col]], axis=0)\n",
    "                assert len(np.unique(row_cols)) == len(row_cols.flatten())\n",
    "                del_idxs = []\n",
    "                for row_node, col_node in row_cols:\n",
    "                    row = np.where( s_np[:,0] == row_node )[0][0]\n",
    "                    col = np.where( s_np[:,0] == col_node )[0][0]\n",
    "\n",
    "                    assert np.all( skel_coords[row] == skel_coords[col] )\n",
    "                    if s_np[row,5] == s_np[col,0] or s_np[col,5] == s_np[row,0]:\n",
    "                        if s_np[row,5] == s_np[col,0]:\n",
    "                            up_idx, down_idx = row, col\n",
    "                        elif s_np[col,5] == s_np[row,0]:\n",
    "                            down_idx, up_idx = row, col\n",
    "                        assert s_np[up_idx,5] == s_np[down_idx,0]\n",
    "\n",
    "                        if np.sum( s_np[up_idx,0] == s_np[:,5] ) > 0:\n",
    "                            # connect node(s) upstream of up_idx to down_idx \n",
    "                            for idx in np.where( s_np[up_idx,0] == s_np[:,5] )[0]:\n",
    "                                s_pandas.at[idx, 'link'] = s_np[down_idx,0]\n",
    "                        del_idxs.append( up_idx )\n",
    "                if len(del_idxs) > 0:\n",
    "                    s_np = s_np[ ~np.isin( np.arange(len(s_np)), del_idxs ) ]\n",
    "                    s_pandas = pd.DataFrame( data = s_np, columns = s_pandas.columns )\n",
    "            assert len(s_np) == len(s_pandas)\n",
    "            # make sure all the leaves can get to the root\n",
    "            leaf_nodes, branch_nodes = utils.find_leaves_and_branches( s_np )\n",
    "            for node in leaf_nodes:\n",
    "                idx = np.where(s_np[:,0] == node)[0][0]\n",
    "                while s_np[idx,5] != -1:\n",
    "                    idx = np.where(s_np[:,0] == s_np[idx,5])[0][0]\n",
    "            \n",
    "            # change direction of theta and phi to ensure they point down the skeleton\n",
    "            new_cols = np.concatenate( [np.array(s_pandas.columns)[:6], ['distance'], np.array(s_pandas.columns)[6:] ] )\n",
    "            s_pandas = skel_clean_utils.append_distance( s_pandas ) # create a distance field in the dataframe\n",
    "            s_pandas = s_pandas.reindex(columns=new_cols)\n",
    "            s_np = s_pandas.to_numpy()\n",
    "            \n",
    "            frac_wrong = 0.0\n",
    "            for idx in range(len(s_np)):\n",
    "                xyz = np.array( utils.spherical_2_cart(1, s_np[idx,7], s_np[idx,8]) )\n",
    "                xyz = xyz / np.sqrt(np.sum(xyz**2))\n",
    "                if s_np[idx,5] != -1:\n",
    "                    down_idx = np.where(s_np[idx,5] == s_np[:,0] )[0][0]\n",
    "                    down_xyz = s_np[ down_idx, [1,2,3]] - s_np[ idx, [1,2,3] ]\n",
    "                    assert np.sqrt(np.sum(down_xyz**2)) > 0\n",
    "                    down_xyz = down_xyz / np.sqrt(np.sum(down_xyz**2))\n",
    "                    assert np.abs( np.sum(down_xyz * xyz) ) < 1.01, f'{down_xyz}, {xyz}, {np.sum(down_xyz * xyz)}'\n",
    "                    if np.sum(down_xyz * xyz) < 0:\n",
    "                        # xyz is pointed in the wrong direction\n",
    "                        _, theta, phi = utils.cart_2_spherical( -xyz[0], -xyz[1], -xyz[2] )\n",
    "                        s_np[idx,7] = theta\n",
    "                        s_np[idx,8] = phi\n",
    "                        frac_wrong += 1 / len(s_np)\n",
    "            node_classes, important_nodes = skel_clean_utils.classify_nodes(s_pandas, fetch_synapses(NC(bodyId=bodyId)), neuron_quality.iloc[i_neuron])\n",
    "            s_pandas['node_classes'] = node_classes\n",
    "            s_pandas.to_csv(new_skel_file, index = False)\n",
    "            print( f'Finished with {bodyId} {neuron_type}' )\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3607e2-0a97-4080-80de-089eac0266b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for neuron_type in config.analyze_neurons:\n",
    "    num_analyzed = 0\n",
    "    for i_neuron in np.where( neuron_type == neuron_quality_np[:,1] )[0]:\n",
    "        bodyId, neuron_type = neuron_quality_np[i_neuron,[0,1]]\n",
    "        new_skel_file = home_dir + f'/saved_clean_skeletons/s_pandas_{bodyId}_{neuron_type}_200nm.csv'\n",
    "        num_analyzed += int( isfile(new_skel_file) )\n",
    "    print( num_analyzed, np.sum( neuron_type == neuron_quality_np[:,1] ), neuron_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b8324-40a2-4222-a8ae-3ed7ca4821d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
