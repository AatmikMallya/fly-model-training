{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d763cc9d-e93d-4b7c-bce4-84b8dea156d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 20:32:57.825110: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-26 20:32:57.837979: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-26 20:32:57.852825: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-26 20:32:57.857281: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-26 20:32:57.868659: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-26 20:33:00.105482: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "swin_unetr.base_5000ep_f48_lr2e-4_pretrained.pt: 244MB [00:07, 36.4MB/s]                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-26 20:33:12,492 - INFO - Downloaded: /tmp/tmpszvpn9eu/swin_unetr.base_5000ep_f48_lr2e-4_pretrained.pt\n",
      "2024-11-26 20:33:12,493 - INFO - Expected md5 is None, skip md5 check for file /tmp/tmpszvpn9eu/swin_unetr.base_5000ep_f48_lr2e-4_pretrained.pt.\n",
      "2024-11-26 20:33:12,493 - INFO - Writing into directory: ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load pretrained weights: Unsupported file type, available options are: [\"zip\", \"tar.gz\", \"tar\"]. name=/tmp/tmpszvpn9eu/swin_unetr.base_5000ep_f48_lr2e-4_pretrained.pt type=.\n",
      "Initializing with random weights\n",
      "using 1 gpu\n",
      "\n",
      "Trainable parameters: 248,089,315 / 248,089,315\n",
      "Found 48 valid image-label pairs\n",
      "Found 48 valid image-label pairs\n",
      "Found 48 valid image-label pairs\n",
      "Training samples: 38\n",
      "Validation samples: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maatmik54\u001b[0m (\u001b[33maatmikmallya\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vast/palmer/home.grace/am3833/fly/segmentation/wandb/run-20241126_203314-2m7poftv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aatmikmallya/microtubule-segmentation/runs/2m7poftv' target=\"_blank\">swinunetr_finetuning</a></strong> to <a href='https://wandb.ai/aatmikmallya/microtubule-segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aatmikmallya/microtubule-segmentation' target=\"_blank\">https://wandb.ai/aatmikmallya/microtubule-segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aatmikmallya/microtubule-segmentation/runs/2m7poftv' target=\"_blank\">https://wandb.ai/aatmikmallya/microtubule-segmentation/runs/2m7poftv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200] Train Loss: 0.13488 Val Loss: 0.05259\n",
      "Epoch [2/200] Train Loss: 0.05343 Val Loss: 0.04731\n",
      "Epoch [3/200] Train Loss: 0.04783 Val Loss: 0.04612\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 338\u001b[0m\n\u001b[1;32m    328\u001b[0m     train_model(\n\u001b[1;32m    329\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    330\u001b[0m         train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    334\u001b[0m         scheduler\u001b[38;5;241m=\u001b[39mscheduler\n\u001b[1;32m    335\u001b[0m     )\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 338\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 328\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    325\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mL1Loss()\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 202\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    200\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m    201\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m--> 202\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# Gradient clipping\u001b[39;00m\n\u001b[1;32m    205\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/jupyterlab_venv/lib/python3.12/site-packages/torch/_tensor.py:572\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m        used to compute the :attr:`tensors`.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    583\u001b[0m )\n",
      "File \u001b[0;32m~/jupyterlab_venv/lib/python3.12/site-packages/torch/overrides.py:1739\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1731\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1732\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1733\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be an error in future, please define it as a classmethod.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1734\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m   1735\u001b[0m     )\n\u001b[1;32m   1737\u001b[0m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> 1739\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/vast/palmer/home.grace/am3833/jupyterlab_venv/src/monai/monai/data/meta_tensor.py:283\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 283\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[0;32m~/jupyterlab_venv/lib/python3.12/site-packages/torch/_tensor.py:1512\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1512\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1514\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/jupyterlab_venv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterlab_venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterlab_venv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# finetune.py\n",
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '0'\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import random\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    RandFlipd,\n",
    "    RandRotate90d,\n",
    "    OneOf,\n",
    ")\n",
    "import datetime\n",
    "import platform\n",
    "from dataset import MicrotubuleDataset\n",
    "\n",
    "# ================== Configuration Variables ==================\n",
    "EXPERIMENT_NAME = 'swinunetr_finetuning'\n",
    "# Data paths\n",
    "IMAGE_DIR = 'training/subvols/image'\n",
    "LABEL_DIR = 'training/labeled_sdt'\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 200\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NUM_WORKERS = 0\n",
    "RANDOM_SEED = 42\n",
    "PATIENCE = 20\n",
    "\n",
    "# Model parameters\n",
    "SPATIAL_DIMS = 3\n",
    "IN_CHANNELS = 1\n",
    "OUT_CHANNELS = 1\n",
    "FEATURE_SIZE = 96  # Reduced from default 48\n",
    "DROP_RATE = 0.3\n",
    "ATTN_DROP_RATE = 0.3\n",
    "DROPOUT_PATH_RATE = 0.3\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device('cuda')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "hyperparameters = {\n",
    "    'experiment_name': EXPERIMENT_NAME,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'weight_decay': WEIGHT_DECAY,\n",
    "    'feature_size': FEATURE_SIZE,\n",
    "    'drop_rate': DROP_RATE,\n",
    "    'attn_drop_rate': ATTN_DROP_RATE,\n",
    "    'dropout_path_rate': DROPOUT_PATH_RATE,\n",
    "    'device': str(DEVICE),\n",
    "    'torch_version': torch.__version__,\n",
    "    'python_version': platform.python_version(),\n",
    "    'training_start_time': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "}\n",
    "\n",
    "# ================== Model Definition ==================\n",
    "class TanhSwinUNETR(nn.Module):\n",
    "    def __init__(self, img_size, in_channels, out_channels, feature_size=48, \n",
    "                 drop_rate=0.0, attn_drop_rate=0.0, dropout_path_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.model = SwinUNETR(\n",
    "            img_size=img_size,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            feature_size=feature_size,\n",
    "            drop_rate=drop_rate,\n",
    "            attn_drop_rate=attn_drop_rate,\n",
    "            dropout_path_rate=dropout_path_rate\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return torch.tanh(x)\n",
    "\n",
    "def initialize_model(pretrained=True):\n",
    "    \"\"\"Initialize SwinUNETR with pretrained weights\"\"\"\n",
    "    model = TanhSwinUNETR(\n",
    "        img_size=(96, 96, 96),\n",
    "        in_channels=IN_CHANNELS,\n",
    "        out_channels=OUT_CHANNELS,\n",
    "        feature_size=FEATURE_SIZE,\n",
    "        drop_rate=DROP_RATE,\n",
    "        attn_drop_rate=ATTN_DROP_RATE,\n",
    "        dropout_path_rate=DROPOUT_PATH_RATE\n",
    "    )\n",
    "    \n",
    "    if pretrained:\n",
    "        try:\n",
    "            from monai.apps import download_and_extract\n",
    "            resource = \"https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/swin_unetr.base_5000ep_f48_lr2e-4_pretrained.pt\"\n",
    "            weightsfile = download_and_extract(resource)\n",
    "            \n",
    "            pretrained_weights = torch.load(weightsfile, map_location='cuda')\n",
    "            model_dict = model.model.state_dict()\n",
    "            pretrained_dict = {k: v for k, v in pretrained_weights.items() \n",
    "                             if k in model_dict and v.shape == model_dict[k].shape}\n",
    "            \n",
    "            model_dict.update(pretrained_dict)\n",
    "            model.model.load_state_dict(model_dict, strict=False)\n",
    "            print(\"Loaded pretrained weights\")\n",
    "            \n",
    "            # Freeze encoder layers\n",
    "            for name, param in model.model.named_parameters():\n",
    "                if 'encoder' in name:\n",
    "                    param.requires_grad = False\n",
    "                    print(f\"Froze {name}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Could not load pretrained weights: {e}\")\n",
    "            print(\"Initializing with random weights\")\n",
    "\n",
    "    # Move model to CUDA and wrap with DataParallel if multiple GPUs available\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "            model = torch.nn.DataParallel(model)\n",
    "        else:\n",
    "            print('using 1 gpu')\n",
    "    else:\n",
    "        print('cuda not available')\n",
    "    model = model.to(DEVICE)\n",
    "    return model\n",
    "\n",
    "# ================== Training Functions ==================\n",
    "def get_transforms():\n",
    "    return Compose([\n",
    "        OneOf([\n",
    "            Compose([]),  # No flips\n",
    "            Compose([RandFlipd(keys=['image', 'label'], prob=1.0, spatial_axis=0)]),\n",
    "            Compose([RandFlipd(keys=['image', 'label'], prob=1.0, spatial_axis=1)]),\n",
    "            Compose([RandFlipd(keys=['image', 'label'], prob=1.0, spatial_axis=2)]),\n",
    "        ], weights=[1/4] * 4),\n",
    "        \n",
    "        OneOf([\n",
    "            Compose([]),  # No rotation\n",
    "            Compose([RandRotate90d(keys=['image', 'label'], prob=1.0, max_k=1, spatial_axes=(0, 1))]),\n",
    "            Compose([RandRotate90d(keys=['image', 'label'], prob=1.0, max_k=1, spatial_axes=(1, 2))]),\n",
    "            Compose([RandRotate90d(keys=['image', 'label'], prob=1.0, max_k=1, spatial_axes=(0, 2))]),\n",
    "        ], weights=[1/4] * 4)\n",
    "    ])\n",
    "\n",
    "def setup_training(model):\n",
    "    encoder_params = []\n",
    "    decoder_params = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:  # Only include unfrozen parameters\n",
    "            if 'encoder' in name:\n",
    "                encoder_params.append(param)\n",
    "            else:\n",
    "                decoder_params.append(param)\n",
    "    \n",
    "    optimizer = optim.AdamW([\n",
    "        {'params': encoder_params, 'lr': LEARNING_RATE * 0.1},\n",
    "        {'params': decoder_params, 'lr': LEARNING_RATE}\n",
    "    ], weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return optimizer, scheduler\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler):\n",
    "    wandb.init(project=\"microtubule-segmentation\", name=EXPERIMENT_NAME, config=hyperparameters)\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Logging\n",
    "        wandb.log({\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'epoch': epoch + 1,\n",
    "            'learning_rate': optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] Train Loss: {avg_train_loss:.5f} Val Loss: {avg_val_loss:.5f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_val_loss,\n",
    "            }, f\"{CHECKPOINT_DIR}/best_model.pt\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f\"Early stopping triggered after epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    wandb.finish()\n",
    "\n",
    "# ================== Main Function ==================\n",
    "def main():\n",
    "    # Create checkpoint directory\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = initialize_model(pretrained=True)\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    # Print parameter summary\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\nTrainable parameters: {trainable_params:,} / {total_params:,}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    transforms = get_transforms()\n",
    "    \n",
    "    dataset = MicrotubuleDataset(\n",
    "        image_dir=IMAGE_DIR,\n",
    "        label_dir=LABEL_DIR\n",
    "    )\n",
    "    \n",
    "    # Split indices\n",
    "    dataset_length = len(dataset)\n",
    "    val_indices = list(range(0, dataset_length, 5))\n",
    "    train_indices = [i for i in range(dataset_length) if i not in val_indices]\n",
    "    \n",
    "    # Create train/val datasets\n",
    "    train_dataset = MicrotubuleDataset(\n",
    "        image_dir=IMAGE_DIR,\n",
    "        label_dir=LABEL_DIR,\n",
    "        indices=train_indices,\n",
    "        transforms=transforms\n",
    "    )\n",
    "    \n",
    "    val_dataset = MicrotubuleDataset(\n",
    "        image_dir=IMAGE_DIR,\n",
    "        label_dir=LABEL_DIR,\n",
    "        indices=val_indices,\n",
    "        transforms=transforms\n",
    "    )\n",
    "    \n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Setup training\n",
    "    optimizer, scheduler = setup_training(model)\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.L1Loss()\n",
    "    \n",
    "    # Train model\n",
    "    train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d142287-1210-425a-b52d-ddfc6d9f4bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python (real venv)",
   "language": "python",
   "name": "jupyterlab_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
