{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f37bc25-900f-43d7-be88-968f2af96536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting files: 100%|██████████| 48/48 [00:01<00:00, 30.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting labels...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting files: 100%|██████████| 49/49 [00:00<00:00, 79.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset.json...\n",
      "\n",
      "Dataset conversion complete! Files are in nnUNet_raw/Dataset001_Microtubules\n",
      "Next steps:\n",
      "1. Run: nnUNetv2_plan_and_preprocess -d 1 --verify_dataset_integrity\n",
      "2. Run your training script\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_dataset_structure():\n",
    "    \"\"\"Create the required directory structure\"\"\"\n",
    "    base_dir = \"nnUNet_raw/Dataset001_Microtubules\"\n",
    "    for subdir in ['imagesTr', 'labelsTr']:\n",
    "        Path(f\"{base_dir}/{subdir}\").mkdir(parents=True, exist_ok=True)\n",
    "    return base_dir\n",
    "\n",
    "def normalize_image(img):\n",
    "    return img.astype(np.float32)\n",
    "\n",
    "def convert_sdt_to_binary(sdt):\n",
    "    \"\"\"Convert signed distance transform to binary mask\n",
    "    SDT range is [-1, 1], where negative values are inside the object\"\"\"\n",
    "    return (sdt <= 0.0001).astype(np.uint8)\n",
    "\n",
    "def convert_to_nifti(source_dir, target_dir, is_label=False, file_prefix=\"\"):\n",
    "    \"\"\"Convert .npy files to .nii.gz files\"\"\"\n",
    "    npy_files = sorted(glob.glob(os.path.join(source_dir, \"*.npy\")))\n",
    "    converted_files = []\n",
    "    \n",
    "    for idx, npy_path in enumerate(tqdm(npy_files, desc=\"Converting files\")):\n",
    "        # Load and process data\n",
    "        data = np.load(npy_path)\n",
    "        \n",
    "        if is_label:\n",
    "            # Convert SDT to binary mask\n",
    "            data = convert_sdt_to_binary(data)\n",
    "        else:\n",
    "            # Normalize image data\n",
    "            data = normalize_image(data)\n",
    "        \n",
    "        # Add channel axis for nnUNet\n",
    "        data = data[np.newaxis, ...]\n",
    "        \n",
    "        # Create NIFTI file\n",
    "        filename = f\"{file_prefix}{idx:03d}.nii.gz\"\n",
    "        nifti_path = os.path.join(target_dir, filename)\n",
    "        \n",
    "        # Create and save NIFTI file with correct orientation\n",
    "        nifti_img = nib.Nifti1Image(data, affine=np.eye(4))\n",
    "        nib.save(nifti_img, nifti_path)\n",
    "        \n",
    "        converted_files.append(filename)\n",
    "    \n",
    "    return converted_files\n",
    "\n",
    "def create_dataset_json(base_dir, image_files, num_training):\n",
    "    \"\"\"Create dataset.json file\"\"\"\n",
    "    dataset_json = {\n",
    "        \"name\": \"Microtubules\",\n",
    "        \"description\": \"Microtubule segmentation in FIBSEM data\",\n",
    "        \"reference\": \"\",\n",
    "        \"licence\": \"\",\n",
    "        \"release\": \"0.0\",\n",
    "        \"tensorImageSize\": \"4D\",\n",
    "        \"modality\": {\n",
    "            \"0\": \"FIBSEM\"\n",
    "        },\n",
    "        \"labels\": {\n",
    "            \"0\": \"background\",\n",
    "            \"1\": \"microtubule\"\n",
    "        },\n",
    "        \"numTraining\": num_training,\n",
    "        \"numTest\": 0,\n",
    "        \"training\": [],\n",
    "        \"test\": []\n",
    "    }\n",
    "    \n",
    "    # Add training cases\n",
    "    for image_file in image_files:\n",
    "        label_file = image_file.replace('image_', 'label_')\n",
    "        dataset_json[\"training\"].append({\n",
    "            \"image\": f\"imagesTr/{image_file}\",\n",
    "            \"label\": f\"labelsTr/{label_file}\"\n",
    "        })\n",
    "    \n",
    "    # Save dataset.json\n",
    "    with open(os.path.join(base_dir, \"dataset.json\"), 'w') as f:\n",
    "        json.dump(dataset_json, f, indent=4)\n",
    "\n",
    "def main():\n",
    "    # Create directory structure\n",
    "    base_dir = create_dataset_structure()\n",
    "    \n",
    "    # Convert images\n",
    "    print(\"Converting images...\")\n",
    "    image_files = convert_to_nifti(\n",
    "        source_dir=\"training/subvols/image\",\n",
    "        target_dir=f\"{base_dir}/imagesTr\",\n",
    "        is_label=False,\n",
    "        file_prefix=\"image_\"\n",
    "    )\n",
    "    \n",
    "    # Convert labels\n",
    "    print(\"Converting labels...\")\n",
    "    convert_to_nifti(\n",
    "        source_dir=\"training/labeled_sdt\",\n",
    "        target_dir=f\"{base_dir}/labelsTr\",\n",
    "        is_label=True,\n",
    "        file_prefix=\"label_\"\n",
    "    )\n",
    "    \n",
    "    # Create dataset.json\n",
    "    print(\"Creating dataset.json...\")\n",
    "    create_dataset_json(base_dir, image_files, num_training=len(image_files))\n",
    "    \n",
    "    print(f\"\\nDataset conversion complete! Files are in {base_dir}\")\n",
    "    print(\"Next steps:\")\n",
    "    print(\"1. Run: nnUNetv2_plan_and_preprocess -d 1 --verify_dataset_integrity\")\n",
    "    print(\"2. Run your training script\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41f24b-4489-4a52-9b16-741aaf4be145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python (real venv)",
   "language": "python",
   "name": "jupyterlab_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
